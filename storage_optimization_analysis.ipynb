{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897f4dee",
   "metadata": {},
   "source": [
    "# Cloud Storage Optimization — Data Analyst Project\n",
    "This notebook analyzes cloud storage logs to identify **cold data**, recommend archival actions, and estimate **potential AWS S3 cost savings**.\n",
    "\n",
    "**Deliverables**: EDA, optimization model, visuals, and exportable summary tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f7060",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c827f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "print('Libraries loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12f817",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44017b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'storage_logs.csv'  # Ensure this file is in the same folder\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['Last_Access_Date'] = pd.to_datetime(df['Last_Access_Date'], errors='coerce')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d903c",
   "metadata": {},
   "source": [
    "## 3. Quick Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isna().sum()\n",
    "duplicates = df.duplicated().sum()\n",
    "print('Missing values by column:\\n', missing)\n",
    "print('\\nDuplicate rows:', duplicates)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141719da",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering — Access Age & Tier Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = pd.Timestamp.today().normalize()\n",
    "df['Days_Since_Access'] = (TODAY - df['Last_Access_Date']).dt.days\n",
    "tier_cost = {'S3 Standard': 0.023, 'S3 IA': 0.0125, 'Glacier': 0.004}\n",
    "df['Cost_per_GB'] = df['Storage_Tier'].map(tier_cost)\n",
    "df['Current_Monthly_Cost'] = (df['Size_GB'] * df['Cost_per_GB']).round(4)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b2694",
   "metadata": {},
   "source": [
    "## 5. Define Cold Data & Potential Savings Model\n",
    "- **Cold data**: `Days_Since_Access > 180`\n",
    "- If cold and not already in Glacier, propose **migrate to Glacier**.\n",
    "- Savings per file = `Current cost - Glacier cost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_cost_per_gb = 0.004\n",
    "df['Is_Cold'] = df['Days_Since_Access'] > 180\n",
    "df['Proposed_Tier'] = np.where(df['Is_Cold'] & (df['Storage_Tier'] != 'Glacier'), 'Glacier', df['Storage_Tier'])\n",
    "df['Proposed_Cost'] = (df['Size_GB'] * np.where(df['Proposed_Tier']=='Glacier', glacier_cost_per_gb, df['Cost_per_GB'])).round(4)\n",
    "df['Potential_Savings'] = (df['Current_Monthly_Cost'] - df['Proposed_Cost']).clip(lower=0).round(4)\n",
    "df[['File_ID','Department','Storage_Tier','Is_Cold','Size_GB','Current_Monthly_Cost','Proposed_Tier','Proposed_Cost','Potential_Savings']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44116675",
   "metadata": {},
   "source": [
    "## 6. Portfolio-Ready KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8762e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost = df['Current_Monthly_Cost'].sum()\n",
    "potential_savings = df['Potential_Savings'].sum()\n",
    "cold_ratio = df['Is_Cold'].mean()\n",
    "kpis = pd.DataFrame({\n",
    "    'Metric': ['Total Current Monthly Cost (USD)', 'Total Potential Monthly Savings (USD)', 'Cold Data Ratio'],\n",
    "    'Value': [round(total_cost,2), round(potential_savings,2), round(cold_ratio*100,2)]\n",
    "})\n",
    "kpis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b314f",
   "metadata": {},
   "source": [
    "## 7. Department-Level Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70187c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_summary = df.groupby('Department').agg(\n",
    "    Files=('File_ID','count'),\n",
    "    Size_GB=('Size_GB','sum'),\n",
    "    Current_Cost=('Current_Monthly_Cost','sum'),\n",
    "    Potential_Savings=('Potential_Savings','sum'),\n",
    "    Cold_Share=('Is_Cold','mean')\n",
    ").reset_index()\n",
    "dept_summary['Cold_Share'] = (dept_summary['Cold_Share']*100).round(2)\n",
    "dept_summary.sort_values('Potential_Savings', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d1c87",
   "metadata": {},
   "source": [
    "## 8. File-Type Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_summary = df.groupby('File_Type').agg(\n",
    "    Files=('File_ID','count'),\n",
    "    Size_GB=('Size_GB','sum'),\n",
    "    Current_Cost=('Current_Monthly_Cost','sum'),\n",
    "    Potential_Savings=('Potential_Savings','sum'),\n",
    "    Cold_Share=('Is_Cold','mean')\n",
    ").reset_index()\n",
    "type_summary['Cold_Share'] = (type_summary['Cold_Share']*100).round(2)\n",
    "type_summary.sort_values('Potential_Savings', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2f82b",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Current cost by storage tier\n",
    "tier_costs = df.groupby('Storage_Tier')['Current_Monthly_Cost'].sum().sort_values()\n",
    "plt.figure()\n",
    "tier_costs.plot(kind='bar')\n",
    "plt.title('Current Monthly Cost by Storage Tier')\n",
    "plt.ylabel('USD')\n",
    "plt.xlabel('Storage Tier')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2 Potential savings by department\n",
    "dept_savings = df.groupby('Department')['Potential_Savings'].sum().sort_values()\n",
    "plt.figure()\n",
    "dept_savings.plot(kind='bar')\n",
    "plt.title('Potential Monthly Savings by Department')\n",
    "plt.ylabel('USD')\n",
    "plt.xlabel('Department')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3 Distribution of days since last access\n",
    "plt.figure()\n",
    "df['Days_Since_Access'].dropna().plot(kind='hist', bins=30)\n",
    "plt.title('Distribution: Days Since Last Access')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d82915",
   "metadata": {},
   "source": [
    "## 10. Actionable Recommendations\n",
    "- Archive cold data (>180 days) not already in Glacier.\n",
    "- Review **Media** and **Backup** file types with high cold share for lifecycle policies.\n",
    "- Implement S3 Lifecycle rules to auto-transition to Glacier after 180 days.\n",
    "- Track KPIs monthly: total cost, cold share, realized savings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd89ee",
   "metadata": {},
   "source": [
    "## 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = 'outputs'\n",
    "import os\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "kpis.to_csv(os.path.join(export_dir,'kpis_summary.csv'), index=False)\n",
    "dept_summary.to_csv(os.path.join(export_dir,'department_summary.csv'), index=False)\n",
    "type_summary.to_csv(os.path.join(export_dir,'filetype_summary.csv'), index=False)\n",
    "recommendations = df.loc[(df['Is_Cold']) & (df['Storage_Tier']!='Glacier'),                          ['File_ID','Department','File_Type','Size_GB','Days_Since_Access','Storage_Tier','Proposed_Tier','Potential_Savings']]\n",
    "recommendations.sort_values('Potential_Savings', ascending=False).to_csv(os.path.join(export_dir,'file_level_recommendations.csv'), index=False)\n",
    "print('Exports written to', export_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed428c9",
   "metadata": {},
   "source": [
    "## 12. Next Steps (Optional Enhancements)\n",
    "- Add **forecasting** for storage growth.\n",
    "- Incorporate **S3 retrieval costs** and **request costs** for a fuller TCO model.\n",
    "- Build a Power BI/Tableau dashboard from the exported CSV summaries.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
